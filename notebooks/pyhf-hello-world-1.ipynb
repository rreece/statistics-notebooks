{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyhf hello world 1\n",
    "\n",
    "Ryan Reece <https://github.com/rreece>        \n",
    "created: 2019-03-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pyhf:\n",
      "\n",
      "NAME\n",
      "    pyhf\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cli (package)\n",
      "    constraints\n",
      "    contrib (package)\n",
      "    events\n",
      "    exceptions (package)\n",
      "    infer (package)\n",
      "    interpolators (package)\n",
      "    mixins\n",
      "    modifiers (package)\n",
      "    optimize (package)\n",
      "    parameters (package)\n",
      "    patchset\n",
      "    pdf\n",
      "    probability\n",
      "    readxml\n",
      "    simplemodels\n",
      "    tensor (package)\n",
      "    utils\n",
      "    version\n",
      "    workspace\n",
      "    writexml\n",
      "\n",
      "CLASSES\n",
      "    builtins.dict(builtins.object)\n",
      "        pyhf.workspace.Workspace(pyhf.mixins._ChannelSummaryMixin, builtins.dict)\n",
      "    builtins.object\n",
      "        pyhf.patchset.PatchSet\n",
      "        pyhf.pdf.Model\n",
      "    pyhf.mixins._ChannelSummaryMixin(builtins.object)\n",
      "        pyhf.workspace.Workspace(pyhf.mixins._ChannelSummaryMixin, builtins.dict)\n",
      "    \n",
      "    class Model(builtins.object)\n",
      "     |  Model(spec, batch_size=None, **config_kwargs)\n",
      "     |  \n",
      "     |  The main pyhf model class.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, spec, batch_size=None, **config_kwargs)\n",
      "     |      Construct a HistFactory Model.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          spec (`jsonable`): The HistFactory JSON specification\n",
      "     |          batch_size (`None` or `int`): Number of simultaneous (batched) Models to compute.\n",
      "     |          config_kwargs: Possible keyword arguments for the model configuration\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          model (`Model`): The Model instance.\n",
      "     |  \n",
      "     |  constraint_logpdf(self, auxdata, pars)\n",
      "     |      Compute the log value of the constraint pdf.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          auxdata (`tensor`): The auxiliary measurement data\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The log density value\n",
      "     |  \n",
      "     |  expected_actualdata(self, pars)\n",
      "     |      Compute the expected value of the main model.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The expected data of the main model (no auxiliary data)\n",
      "     |  \n",
      "     |  expected_auxdata(self, pars)\n",
      "     |      Compute the expected value of the auxiliary measurements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The expected data of the auxiliary pdf\n",
      "     |  \n",
      "     |  expected_data(self, pars, include_auxdata=True)\n",
      "     |      Compute the expected value of the main model\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The expected data of the main and auxiliary model\n",
      "     |  \n",
      "     |  logpdf(self, pars, data)\n",
      "     |      Compute the log value of the full density.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |          data (`tensor`): The measurement data\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The log density value\n",
      "     |  \n",
      "     |  mainlogpdf(self, maindata, pars)\n",
      "     |      Compute the log value of the main term.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          maindata (`tensor`): The main measurement data\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The log density value\n",
      "     |  \n",
      "     |  make_pdf(self, pars)\n",
      "     |      Construct a pdf object for a given set of parameter values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The model parameters\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          pdf: A distribution object implementing the main measurement pdf of HistFactory\n",
      "     |  \n",
      "     |  pdf(self, pars, data)\n",
      "     |      Compute the density at a given observed point in data space of the full model.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          pars (`tensor`): The parameter values\n",
      "     |          data (`tensor`): The measurement data\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: The density value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  nominal_rates\n",
      "     |      Nominal value of bin rates of the main model.\n",
      "    \n",
      "    class PatchSet(builtins.object)\n",
      "     |  PatchSet(spec, **config_kwargs)\n",
      "     |  \n",
      "     |  A way to store a collection of patches (:class:`~pyhf.patchset.Patch`).\n",
      "     |  \n",
      "     |  It contains :attr:`~PatchSet.metadata` about the PatchSet itself:\n",
      "     |  \n",
      "     |    * a high-level :attr:`~pyhf.patchset.PatchSet.description` of what the patches represent or the analysis it is for\n",
      "     |    * a list of :attr:`~pyhf.patchset.PatchSet.references` where the patchset is sourced from (e.g. hepdata)\n",
      "     |    * a list of :attr:`~pyhf.patchset.PatchSet.digests` corresponding to the background-only workspace the patchset was made for\n",
      "     |    * the :attr:`~pyhf.patchset.PatchSet.labels` of the dimensions of the phase-space for what the patches cover\n",
      "     |  \n",
      "     |  In addition to the above metadata, the PatchSet object behaves like a:\n",
      "     |  \n",
      "     |    * smart list allowing you to iterate over all the patches defined\n",
      "     |    * smart dictionary allowing you to access a patch by the patch name or the patch values\n",
      "     |  \n",
      "     |  The below example shows various ways one can interact with a :class:`PatchSet` object.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      >>> import pyhf\n",
      "     |      >>> patchset = pyhf.PatchSet({\n",
      "     |      ...     \"metadata\": {\n",
      "     |      ...         \"references\": { \"hepdata\": \"ins1234567\" },\n",
      "     |      ...         \"description\": \"example patchset\",\n",
      "     |      ...         \"digests\": { \"md5\": \"098f6bcd4621d373cade4e832627b4f6\" },\n",
      "     |      ...         \"labels\": [\"x\", \"y\"]\n",
      "     |      ...     },\n",
      "     |      ...     \"patches\": [\n",
      "     |      ...         {\n",
      "     |      ...             \"metadata\": {\n",
      "     |      ...                 \"name\": \"patch_name_for_2100x_800y\",\n",
      "     |      ...                 \"values\": [2100, 800]\n",
      "     |      ...             },\n",
      "     |      ...             \"patch\": [\n",
      "     |      ...                 {\n",
      "     |      ...                     \"op\": \"add\",\n",
      "     |      ...                     \"path\": \"/foo/0/bar\",\n",
      "     |      ...                     \"value\": {\n",
      "     |      ...                         \"foo\": [1.0]\n",
      "     |      ...                     }\n",
      "     |      ...                 }\n",
      "     |      ...             ]\n",
      "     |      ...         }\n",
      "     |      ...     ],\n",
      "     |      ...     \"version\": \"1.0.0\"\n",
      "     |      ... })\n",
      "     |      ...\n",
      "     |      >>> patchset.version\n",
      "     |      '1.0.0'\n",
      "     |      >>> patchset.references\n",
      "     |      {'hepdata': 'ins1234567'}\n",
      "     |      >>> patchset.description\n",
      "     |      'example patchset'\n",
      "     |      >>> patchset.digests\n",
      "     |      {'md5': '098f6bcd4621d373cade4e832627b4f6'}\n",
      "     |      >>> patchset.labels\n",
      "     |      ['x', 'y']\n",
      "     |      >>> patchset.patches\n",
      "     |      [<pyhf.patchset.Patch object 'patch_name_for_2100x_800y(2100, 800)' at 0x...>]\n",
      "     |      >>> patchset['patch_name_for_2100x_800y']\n",
      "     |      <pyhf.patchset.Patch object 'patch_name_for_2100x_800y(2100, 800)' at 0x...>\n",
      "     |      >>> patchset[(2100,800)]\n",
      "     |      <pyhf.patchset.Patch object 'patch_name_for_2100x_800y(2100, 800)' at 0x...>\n",
      "     |      >>> patchset[[2100,800]]\n",
      "     |      <pyhf.patchset.Patch object 'patch_name_for_2100x_800y(2100, 800)' at 0x...>\n",
      "     |      >>> patchset[2100,800]\n",
      "     |      <pyhf.patchset.Patch object 'patch_name_for_2100x_800y(2100, 800)' at 0x...>\n",
      "     |      >>> for patch in patchset:\n",
      "     |      ...     print(patch.name)\n",
      "     |      ...\n",
      "     |      patch_name_for_2100x_800y\n",
      "     |      >>> len(patchset)\n",
      "     |      1\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Access the patch in the patchset by the specified key, either by name or by values.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ~pyhf.exceptions.InvalidPatchLookup: if the provided patch name is not in the patchset\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          patch (:class:`~pyhf.patchset.Patch`): The patch associated with the specified key\n",
      "     |  \n",
      "     |  __init__(self, spec, **config_kwargs)\n",
      "     |      Construct a PatchSet.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          spec (`jsonable`): The patchset JSON specification\n",
      "     |          config_kwargs: Possible keyword arguments for the patchset validation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          patchset (:class:`~pyhf.patchset.PatchSet`): The PatchSet instance.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate over the defined patches in the patchset.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          iterable (:obj:`iter`): An iterable over the list of patches in the patchset.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The number of patches in the patchset.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          quantity (:obj:`int`): The number of patches in the patchset.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Representation of the object\n",
      "     |  \n",
      "     |  apply(self, spec, key)\n",
      "     |      Apply the patch associated with the key to the background-only workspace specificatiom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          spec (:class:`~pyhf.workspace.Workspace`): The workspace specification to verify the patchset against.\n",
      "     |          key (:obj:`str` or :obj:`tuple` of :obj:`int`/:obj:`float`): The key to look up the associated patch - either a name or a set of values.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ~pyhf.exceptions.InvalidPatchLookup: if the provided patch name is not in the patchset\n",
      "     |          ~pyhf.exceptions.PatchSetVerificationError: if the patchset cannot be verified against the workspace specification\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          workspace (:class:`~pyhf.workspace.Workspace`): The background-only workspace with the patch applied.\n",
      "     |  \n",
      "     |  verify(self, spec)\n",
      "     |      Verify the patchset digests against a background-only workspace specification. Verified if no exception was raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          spec (:class:`~pyhf.workspace.Workspace`): The workspace specification to verify the patchset against.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ~pyhf.exceptions.PatchSetVerificationError: if the patchset cannot be verified against the workspace specification\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  description\n",
      "     |      The description in the PatchSet metadata\n",
      "     |  \n",
      "     |  digests\n",
      "     |      The digests in the PatchSet metadata\n",
      "     |  \n",
      "     |  labels\n",
      "     |      The labels in the PatchSet metadata\n",
      "     |  \n",
      "     |  metadata\n",
      "     |      The metadata of the PatchSet\n",
      "     |  \n",
      "     |  patches\n",
      "     |      The patches in the PatchSet\n",
      "     |  \n",
      "     |  references\n",
      "     |      The references in the PatchSet metadata\n",
      "     |  \n",
      "     |  version\n",
      "     |      The version of the PatchSet\n",
      "    \n",
      "    class Workspace(pyhf.mixins._ChannelSummaryMixin, builtins.dict)\n",
      "     |  Workspace(spec, **config_kwargs)\n",
      "     |  \n",
      "     |  A JSON-serializable object that is built from an object that follows the :obj:`workspace.json` `schema <https://scikit-hep.org/pyhf/likelihood.html#workspace>`__.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Workspace\n",
      "     |      pyhf.mixins._ChannelSummaryMixin\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Equality is defined as equal dict representations.\n",
      "     |  \n",
      "     |  __init__(self, spec, **config_kwargs)\n",
      "     |      Workspaces hold the model, data and measurements.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Negation of equality.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Representation of the Workspace.\n",
      "     |  \n",
      "     |  data(self, model, with_aux=True)\n",
      "     |      Return the data for the supplied model with or without auxiliary data from the model.\n",
      "     |      \n",
      "     |      The model is needed as the order of the data depends on the order of the channels in the model.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        KeyError: Invalid or missing channel\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          model (~pyhf.pdf.Model): A model object adhering to the schema model.json\n",
      "     |          with_aux (bool): Whether to include auxiliary data from the model or not\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          :obj:`list`: data\n",
      "     |  \n",
      "     |  get_measurement(self, poi_name=None, measurement_name=None, measurement_index=None)\n",
      "     |      Get (or create) a measurement object.\n",
      "     |      \n",
      "     |      The following logic is used:\n",
      "     |      \n",
      "     |        1. if the poi name is given, create a measurement object for that poi\n",
      "     |        2. if the measurement name is given, find the measurement for the given name\n",
      "     |        3. if the measurement index is given, return the measurement at that index\n",
      "     |        4. if there are measurements but none of the above have been specified, return the 0th measurement\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ~pyhf.exceptions.InvalidMeasurement: If the measurement was not found\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          poi_name (`str`): The name of the parameter of interest to create a new measurement from\n",
      "     |          measurement_name (`str`): The name of the measurement to use\n",
      "     |          measurement_index (`int`): The index of the measurement to use\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          :obj:`dict`: A measurement object adhering to the schema defs.json#/definitions/measurement\n",
      "     |  \n",
      "     |  model(self, **config_kwargs)\n",
      "     |      Create a model object with/without patches applied.\n",
      "     |      \n",
      "     |      See :func:`pyhf.workspace.Workspace.get_measurement` and :class:`pyhf.pdf.Model` for possible keyword arguments.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          patches: A list of JSON patches to apply to the model specification\n",
      "     |          config_kwargs: Possible keyword arguments for the measurement and model configuration\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          ~pyhf.pdf.Model: A model object adhering to the schema model.json\n",
      "     |  \n",
      "     |  prune(self, modifiers=None, modifier_types=None, samples=None, channels=None, measurements=None)\n",
      "     |      Return a new, pruned workspace specification. This will not modify the original workspace.\n",
      "     |      \n",
      "     |      The pruned workspace must also be a valid workspace.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          modifiers: A :obj:`str` or a :obj:`list` of modifiers to prune.\n",
      "     |          modifier_types: A :obj:`str` or a :obj:`list` of modifier types to prune.\n",
      "     |          samples: A :obj:`str` or a :obj:`list` of samples to prune.\n",
      "     |          channels: A :obj:`str` or a :obj:`list` of channels to prune.\n",
      "     |          measurements: A :obj:`str` or a :obj:`list` of measurements to prune.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          ~pyhf.workspace.Workspace: A new workspace object with the specified components removed\n",
      "     |  \n",
      "     |  rename(self, modifiers=None, samples=None, channels=None, measurements=None)\n",
      "     |      Return a new workspace specification with certain elements renamed.\n",
      "     |      \n",
      "     |      This will not modify the original workspace.\n",
      "     |      The renamed workspace must also be a valid workspace.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          modifiers: A :obj:`dict` mapping old modifier name to new modifier name.\n",
      "     |          samples: A :obj:`dict` mapping old sample name to new sample name.\n",
      "     |          channels: A :obj:`dict` mapping old channel name to new channel name.\n",
      "     |          measurements: A :obj:`dict` mapping old measurement name to new measurement name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          ~pyhf.workspace.Workspace: A new workspace object with the specified components renamed\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  combine(left, right, join='none') from builtins.type\n",
      "     |      Return a new workspace specification that is the combination of the two workspaces.\n",
      "     |      \n",
      "     |      The new workspace must also be a valid workspace. A combination of\n",
      "     |      workspaces is done by combining the set of:\n",
      "     |      \n",
      "     |        - channels,\n",
      "     |        - observations, and\n",
      "     |        - measurements\n",
      "     |      \n",
      "     |      between the two workspaces. If the two workspaces have modifiers that\n",
      "     |      follow the same naming convention, then correlations across the two\n",
      "     |      workspaces may be possible. In particular, the `lumi` modifier will be\n",
      "     |      fully-correlated.\n",
      "     |      \n",
      "     |      If the two workspaces have the same measurement (with the same POI),\n",
      "     |      those measurements will get merged.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ~pyhf.exceptions.InvalidWorkspaceOperation: The workspaces have common channel names, incompatible measurements, or incompatible schema versions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          left (~pyhf.workspace.Workspace): A workspace\n",
      "     |          right (~pyhf.workspace.Workspace): Another workspace\n",
      "     |          join (:obj:`str`): How to join the two workspaces. Pick from \"none\", \"outer\", \"left outer\", or \"right outer\".\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          ~pyhf.workspace.Workspace: A new combined workspace object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  valid_joins = ['none', 'outer', 'left outer', 'right outer']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      x.__getitem__(y) <==> x[y]\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |  \n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      "     |  \n",
      "     |  popitem(...)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      "     |      2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |      \n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |  \n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  fromkeys(iterable, value=None, /) from builtins.type\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Model', 'Workspace', 'PatchSet', 'infer', 'utils', 'modifi...\n",
      "\n",
      "VERSION\n",
      "    0.4.3\n",
      "\n",
      "FILE\n",
      "    /Users/reece/at-github/statistics-notebooks/env1/lib/python3.7/site-packages/pyhf/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pyhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pyhf.simplemodels in pyhf:\n",
      "\n",
      "NAME\n",
      "    pyhf.simplemodels\n",
      "\n",
      "FUNCTIONS\n",
      "    hepdata_like(signal_data, bkg_data, bkg_uncerts, batch_size=None)\n",
      "\n",
      "FILE\n",
      "    /Users/reece/at-github/statistics-notebooks/env1/lib/python3.7/site-packages/pyhf/simplemodels.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pyhf.simplemodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hepdata_like in module pyhf.simplemodels:\n",
      "\n",
      "hepdata_like(signal_data, bkg_data, bkg_uncerts, batch_size=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pyhf.simplemodels.hepdata_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pyhf.utils.hypotest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [pyhf.infer.hypotest](https://scikit-hep.org/pyhf/_generated/pyhf.infer.hypotest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pyhf.simplemodels.hepdata_like(signal_data=[12.0, 11.0], bkg_data=[50.0, 52.0], bkg_uncerts=[3.0, 7.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[277.77777777777777, 55.183673469387756]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed: [0.05290116], Expected: [0.06445521]\n"
     ]
    }
   ],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(1.0, [51, 48] + pdf.config.auxdata, pdf, return_expected=True)\n",
    "print('Observed: {}, Expected: {}'.format(CLs_obs, CLs_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_and_register_paramsets',\n",
       " 'auxdata',\n",
       " 'auxdata_order',\n",
       " 'channel_nbins',\n",
       " 'channels',\n",
       " 'modifier_settings',\n",
       " 'modifiers',\n",
       " 'nauxdata',\n",
       " 'nmaindata',\n",
       " 'npars',\n",
       " 'par_map',\n",
       " 'par_order',\n",
       " 'par_slice',\n",
       " 'param_set',\n",
       " 'parameters',\n",
       " 'poi_index',\n",
       " 'poi_name',\n",
       " 'samples',\n",
       " 'set_poi',\n",
       " 'suggested_bounds',\n",
       " 'suggested_init']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pdf.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uncorr_bkguncrt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.auxdata_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'singlechannel': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.channel_nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mu', 'normfactor'), ('uncorr_bkguncrt', 'shapesys')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mu', 'uncorr_bkguncrt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.poi_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 10), (1e-10, 10.0), (1e-10, 10.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.config.suggested_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "-   <https://scikit-hep.org/pyhf/>\n",
    "-   Cowan, G. et al. (2010). Asymptotic formulae for likelihood-based tests of new physics. https://arxiv.org/abs/1007.1727\n",
    "-   Cranmer, K. et al. (2012). HistFactory: A tool for creating statistical models for use with RooFit and RooStats. CERN-OPEN-2012-016. <https://cds.cern.ch/record/1456844>\n",
    "-   Feickert, M. (2018). pyhf: a pure Python implementation of HistFactory with tensors and autograd. <https://indico.cern.ch/event/759480/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
