{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hep stats hello world\n",
    "\n",
    "Ryan Reece <https://github.com/rreece>        \n",
    "created: 2020-07-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "-   ~~Revist conventions for storing results of hypo tests: `CLs_obs, CLs_exp_band`~~\n",
    "-   ~~Clean up function above for plotting mu excluded vs one theoretical param.~~\n",
    "-   ~~Write Z-peak-like example.~~\n",
    "-   ~~Try ToyCalculator instead of AsymptoticCalculator.~~\n",
    "-   ~~Generate data with injected signal.~~\n",
    "-   ~~Fix hep.plot.hist1d ylim default range.~~\n",
    "-   Fix for handeling the total number of events; extended maximum likelihood.\n",
    "-   Write functions for showing hists pre and post fit.\n",
    "-   Understand what [pyhf.infer.hypotest](https://scikit-hep.org/pyhf/_generated/pyhf.infer.hypotest.html) does in detail.\n",
    "-   Understand where all the implicit fitting and computation is and document it. Time the execution of parts.\n",
    "-   ~~Calculate p_0 for discovery.~~\n",
    "-   ~~Write a 2-sided measurement of signal with t_mu.~~\n",
    "-   Re-use bkg toys in case of ToyCalculator.\n",
    "-   How to add systematics in pyhf?\n",
    "-   Remind myself and understand the interpolations used.\n",
    "-   Side-band analysis of fakes, ABCD.\n",
    "-   Add splining option to hep.plot.brazil.\n",
    "-   Write a function for plotting an exclusion contour in 2-D theoretical paramter space.\n",
    "-   https://stackoverflow.com/questions/64538170/using-pyhf-to-float-both-signal-and-background-strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pyhf\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import cauchy, truncexpon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hepplot as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: following\n",
    "\n",
    "-    [multichannel-coupled-histo.html](https://scikit-hep.org/pyhf/examples/notebooks/multichannel-coupled-histo.html)\n",
    "-    [2bin_2channel_coupledhisto.json](https://github.com/scikit-hep/pyhf/blob/master/validation/data/2bin_2channel_coupledhisto.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedata = {\n",
    "  \"channels\": {\n",
    "    \"signal\": {\n",
    "      \"binning\": [2, -0.5, 1.5],\n",
    "      \"bindata\": {\n",
    "        \"data\":       [170.0, 220.0],\n",
    "        \"bkg1\":       [100.0, 100.0],\n",
    "        \"bkg1_up\":    [110.0, 110.0],\n",
    "        \"bkg1_dn\":      [90.0, 90.0],\n",
    "        \"bkg2\":        [50.0, 120.0],\n",
    "        \"bkg2_up\":     [55.0, 55.0],\n",
    "        \"bkg2_dn\":     [45.0, 45.0],\n",
    "        \"sig\":          [30.0, 35.0]\n",
    "      }\n",
    "    },\n",
    "    \"control\": {\n",
    "      \"binning\": [2, -0.5, 1.5],\n",
    "      \"bindata\": {\n",
    "        \"data\":     [110.0, 105.0],\n",
    "        \"bkg1\":     [105.0, 100.0],\n",
    "        \"bkg1_up\":  [110.0, 115.0],\n",
    "        \"bkg1_dn\":    [95.0, 90.0]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(sourcedata):\n",
    "    spec = {\n",
    "        \"channels\": [\n",
    "            {\n",
    "                \"name\": \"signal\",\n",
    "                \"samples\": [\n",
    "                    {\n",
    "                        \"name\": \"signal\",\n",
    "                        \"data\": sourcedata[\"signal\"][\"bindata\"][\"sig\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"bkg1\",\n",
    "                        \"data\": sourcedata[\"signal\"][\"bindata\"][\"bkg1\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\n",
    "                                \"name\": \"coupled_histosys\",\n",
    "                                \"type\": \"histosys\",\n",
    "                                \"data\": {\n",
    "                                    \"lo_data\": sourcedata[\"signal\"][\"bindata\"][\n",
    "                                        \"bkg1_dn\"\n",
    "                                    ],\n",
    "                                    \"hi_data\": sourcedata[\"signal\"][\"bindata\"][\n",
    "                                        \"bkg1_up\"\n",
    "                                    ],\n",
    "                                },\n",
    "                            }\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"bkg2\",\n",
    "                        \"data\": sourcedata[\"signal\"][\"bindata\"][\"bkg2\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\n",
    "                                \"name\": \"coupled_histosys\",\n",
    "                                \"type\": \"histosys\",\n",
    "                                \"data\": {\n",
    "                                    \"lo_data\": sourcedata[\"signal\"][\"bindata\"][\n",
    "                                        \"bkg2_dn\"\n",
    "                                    ],\n",
    "                                    \"hi_data\": sourcedata[\"signal\"][\"bindata\"][\n",
    "                                        \"bkg2_up\"\n",
    "                                    ],\n",
    "                                },\n",
    "                            }\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"control\",\n",
    "                \"samples\": [\n",
    "                    {\n",
    "                        \"name\": \"background\",\n",
    "                        \"data\": sourcedata[\"control\"][\"bindata\"][\"bkg1\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\n",
    "                                \"name\": \"coupled_histosys\",\n",
    "                                \"type\": \"histosys\",\n",
    "                                \"data\": {\n",
    "                                    \"lo_data\": sourcedata[\"control\"][\"bindata\"][\n",
    "                                        \"bkg1_dn\"\n",
    "                                    ],\n",
    "                                    \"hi_data\": sourcedata[\"control\"][\"bindata\"][\n",
    "                                        \"bkg1_up\"\n",
    "                                    ],\n",
    "                                },\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    pdf = pyhf.Model(spec)\n",
    "    data = []\n",
    "    for c in pdf.spec[\"channels\"]:\n",
    "        data += sourcedata[c[\"name\"]][\"bindata\"][\"data\"]\n",
    "    data = data + pdf.config.auxdata\n",
    "    return data, pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"2bin_2channel_coupledhisto.json\"\n",
    "source = json.load(open(json_filename))\n",
    "data, pdf = prep_data(source[\"channels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMI = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 80.\n",
    "x_max = 180.\n",
    "n_xbins = 20\n",
    "xlabel = '$m\\ \\ [\\mathrm{GeV}]$'\n",
    "ylabel = '$dN/dm\\ /\\ (5\\ \\mathrm{GeV})$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normal params\n",
    "mu_bounds_excl = (0, 5)\n",
    "mu_step_excl = 0.1\n",
    "test_size = 0.05\n",
    "mu_bounds_fit = (-0.5, 2.0)\n",
    "mu_step_fit = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine params\n",
    "#mu_bounds_excl = (0, 4)\n",
    "#mu_step_excl = 0.05\n",
    "#test_size = 0.05\n",
    "#mu_bounds_fit = (-0.5, 2.0)\n",
    "#mu_step_fit = 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background params\n",
    "m_Z = 91.2\n",
    "gamma_Z = 2.5\n",
    "func_Z = cauchy(loc=m_Z, scale=gamma_Z)\n",
    "sigma_Z = 9000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_fakes = x_min\n",
    "scale_fakes = 100.\n",
    "b_fakes = x_max\n",
    "func_fakes = truncexpon(b_fakes, loc=loc_fakes, scale=scale_fakes)\n",
    "sigma_fakes = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## signal params\n",
    "signal_masses = [110., 130., 150., 170.]\n",
    "#signal_masses = [110., 120., 130., 140., 150., 160., 170.]\n",
    "max_signals_plotted = 4\n",
    "\n",
    "## fine params\n",
    "#signal_masses = [110., 115., 120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.]\n",
    "#max_signals_plotted = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_tot = sigma_Z + sigma_fakes\n",
    "f_Z = sigma_Z / sigma_tot\n",
    "f_fakes = sigma_fakes / sigma_tot\n",
    "bkg_sigmas = [sigma_Z, sigma_fakes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_labels = ['$s_{%i}$' % (m) for m in signal_masses ]\n",
    "signal_widths = [ 0.02*m for m in signal_masses ]\n",
    "signal_funcs = [ cauchy(loc=m, scale=w) for m, w in zip(signal_masses, signal_widths) ]\n",
    "signal_sigmas = [ 150. - 0.5*m for m in signal_masses ]\n",
    "i_signal_injected = signal_masses.index(150.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pdfs and normalize them over linspace x\n",
    "x = np.linspace(x_min, x_max, n_xbins)\n",
    "pdf_Z = func_Z.pdf(x)\n",
    "pdf_fakes = func_fakes.pdf(x)\n",
    "n_Z = sum(pdf_Z)\n",
    "n_fakes = sum(pdf_fakes)\n",
    "pdf_Z = pdf_Z / n_Z\n",
    "pdf_fakes = pdf_fakes / n_fakes\n",
    "pdf_tot1 = f_Z*pdf_Z + f_fakes*pdf_fakes\n",
    "assert np.allclose(sum(pdf_Z), 1.0)\n",
    "assert np.allclose(sum(pdf_fakes), 1.0)\n",
    "assert np.allclose(sum([f_Z, f_fakes]), 1.0)\n",
    "assert np.allclose(sum(pdf_tot1), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_fakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "xlims=(x_min, x_max)\n",
    "ylims=(0.0, 0.15)\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "ax.plot(x, pdf_fakes, 'r-', lw=5, alpha=0.6, label='fakes')\n",
    "ax.plot(x, pdf_Z, 'b-', lw=5, alpha=0.6, label='Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make DataGenerator with mixture of pdfs\n",
    "bkg_funcs = [func_Z, func_fakes]\n",
    "bkg_mixtures = [f_Z, f_fakes]\n",
    "bkg_gen = hep.data.DataGenerator(funcs=bkg_funcs, mixtures=bkg_mixtures)\n",
    "bkg_pdf = bkg_gen.get_pdf(x)\n",
    "assert np.allclose(bkg_pdf, pdf_tot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_gens = [ hep.data.DataGenerator(funcs=[_func], mixtures=[1.0]) for _func in signal_funcs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "xlims=(x_min, x_max)\n",
    "#ylims=(0.0, 0.15)\n",
    "ylims=(1e-3, 0.15) # logy\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "ax.set_yscale('log')\n",
    "ax.plot(x, bkg_pdf, 'k-', lw=5, alpha=0.6, label='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test = bkg_gen.generate(1000, i=1)\n",
    "y_test = np.histogram(a_test, bins=n_xbins, range=(x_min, x_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bkgs = bkg_gen.get_n()\n",
    "assert len(bkg_sigmas) == n_bkgs\n",
    "n_mcs = [int(1e5), int(1e5)]\n",
    "bkg_hists = [ np.histogram(bkg_gen.generate(n_mcs[_i], i=_i), bins=n_xbins, range=(x_min, x_max))[0] for _i in range(n_bkgs)]\n",
    "bkg_scales = [ bkg_sigmas[_i]*LUMI/n_mcs[_i] for _i in range(n_bkgs) ]\n",
    "bkg_hists = [ list(bkg_hists[_i] * bkg_scales[_i]) for _i in range(n_bkgs) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [ float(_b) for _b in y_test[1] ]\n",
    "y = bkg_hists\n",
    "xlabel = '$m$  [GeV]'\n",
    "ylabel = 'Events / (5 GeV)'\n",
    "labels = ['Z','Fakes']\n",
    "ytotal  = [sum(_y) for _y in zip(*y)]\n",
    "\n",
    "## gaussian errors\n",
    "yerr    = [\n",
    "    math.sqrt(_y) for _y in ytotal\n",
    "]\n",
    "# TODO: yerr should be better that sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signals = [ int(round(s*LUMI)) for s in signal_sigmas ]\n",
    "signal_grid = dict()\n",
    "for _m, _sg, _n in zip(signal_masses, sig_gens, n_signals):\n",
    "    _x = _sg.generate(_n)\n",
    "    signal_grid[(_m,)] = list(np.histogram(_x, bins=n_xbins, range=(x_min, x_max))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_points = list(signal_grid.keys())\n",
    "signal_points.sort()\n",
    "signals = [signal_grid[k] for k in signal_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = int(round(sigma_tot*LUMI))\n",
    "data = list(np.histogram(bkg_gen.generate(n_data), bins=n_xbins, range=(x_min, x_max))[0])\n",
    "data_label='Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.hist1d(bins, y,\n",
    "                yerr=yerr,\n",
    "                labels=labels,\n",
    "                data=data,\n",
    "                data_label=data_label,\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                xlim=(x_min, x_max),\n",
    "#                ylim=(10., 1e4),\n",
    "                yscale='log',\n",
    "                ratio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.hist1d(bins, y,\n",
    "                yerr=yerr,\n",
    "                labels=labels,\n",
    "                data=data,\n",
    "                data_label=data_label,\n",
    "                signals=signals[-max_signals_plotted:],\n",
    "                signal_labels=signal_labels[-max_signals_plotted:],\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                xlim=(110, 180),\n",
    "#                ylim=(0.0, 160.0),\n",
    "                ratio=True,\n",
    "                stack_signals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing with pyhf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "-   Explain `pyhf.simplemodels.hepdata_like`\n",
    "    -   Marked Poisson\n",
    "    -   Cranmer, K. et al. (2012). HistFactory: A tool for creating statistical models for use with RooFit and RooStats. CERN-OPEN-2012-016. <https://cds.cern.ch/record/1456844>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic hypothesis test at mu=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_results = list()\n",
    "for i_signal, signal in enumerate(signals[-max_signals_plotted:]):\n",
    "    print('Testing signal %i' % (i_signal+1))\n",
    "    pdf = hep.stats.make_pdf(bkg_data=ytotal, bkg_uncerts=yerr, signal_data=signal)\n",
    "    CLs_obs, CLs_exp_band = hep.stats.hypo_test(pdf=pdf, data=data, mu=1.0)\n",
    "    results = dict()\n",
    "    results['pdf'] = pdf\n",
    "    results['CLs_obs'] = CLs_obs\n",
    "    results['CLs_exp_band'] = CLs_exp_band\n",
    "    list_of_results.append(results)\n",
    "    print('Expected CLs -2 sigma: %.4f' % (CLs_exp_band[0]))\n",
    "    print('Expected CLs -1 sigma: %.4f' % (CLs_exp_band[1]))\n",
    "    print('Expected CLs         : %.4f' % (CLs_exp_band[2]))\n",
    "    print('Expected CLs +1 sigma: %.4f' % (CLs_exp_band[3]))\n",
    "    print('Expected CLs +2 sigma: %.4f' % (CLs_exp_band[4]))\n",
    "    print('Observed CLs         : %.4f' % (CLs_obs))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pyhf.simplemodels.uncorrelated_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis test scan for a single signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_signal_pdf = hep.stats.make_pdf(bkg_data=ytotal, bkg_uncerts=yerr, signal_data=signals[0])\n",
    "cls_obs, cls_exp, test_mus = hep.stats.hypo_test_mu_scan(pdf=first_signal_pdf, \n",
    "                                                      data=data, \n",
    "                                                      mu_bounds=mu_bounds_excl,\n",
    "                                                      mu_step=mu_step_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.brazil(x=test_mus, exp=cls_exp, obs=cls_obs,\n",
    "                     xlabel=r'$\\mu$',\n",
    "                     ylabel=r'$\\mathrm{CLs}$',\n",
    "                     xlim=mu_bounds_excl,\n",
    "                     ylim=(0.0, 1.0),\n",
    "                     yline=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.stats.invert_interval(cls_obs, cls_exp, test_mus, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis test scan across signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ms, exclusions_exp, exclusions_obs = hep.stats.hypo_test_signal_scan(\n",
    "        signal_grid=signal_grid,\n",
    "        data=data,\n",
    "        bkg_data=ytotal,\n",
    "        bkg_uncerts=yerr,\n",
    "        mu_bounds=mu_bounds_excl,\n",
    "        mu_step=mu_step_excl,\n",
    "        test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.brazil(x=signal_ms, exp=exclusions_exp, obs=exclusions_obs,\n",
    "                xlabel=r'$m$  [GeV]',\n",
    "                ylabel=r'$\\mu\\ \\mathrm{excluded\\ at\\ 95\\%\\ CL}$',\n",
    "                yline=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injecting signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_func = signal_funcs[i_signal_injected]\n",
    "sig_sigma = signal_sigmas[i_signal_injected]\n",
    "injection_funcs = bkg_funcs + [sig_func]\n",
    "pdf_sig = sig_func.pdf(x)\n",
    "\n",
    "sigma_tot2 = sigma_Z + sigma_fakes + sig_sigma\n",
    "f_Z2 = sigma_Z / sigma_tot2\n",
    "f_fakes2 = sigma_fakes / sigma_tot2\n",
    "f_sig2 = sig_sigma / sigma_tot2\n",
    "\n",
    "injection_mixtures = [f_Z2, f_fakes2, f_sig2]\n",
    "pdf_tot2 = f_Z2*pdf_Z + f_fakes2*pdf_fakes + f_sig2*pdf_sig\n",
    "injection_gen = hep.data.DataGenerator(funcs=injection_funcs, mixtures=injection_mixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_tot2, sigma_Z, sigma_fakes, sig_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data2 = int(round(sigma_tot2*LUMI))\n",
    "data2 = list(np.histogram(injection_gen.generate(n_data2), bins=n_xbins, range=(x_min, x_max))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.hist1d(bins, y,\n",
    "                yerr=yerr,\n",
    "                labels=labels,\n",
    "                data=data2,\n",
    "                data_label=data_label,\n",
    "                signals=[signals[i_signal_injected]],\n",
    "                signal_labels=[signal_labels[i_signal_injected]],\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                xlim=(x_min, x_max),\n",
    "#                ylim=(10., 1e4),\n",
    "                yscale='log',\n",
    "                ratio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.hist1d(bins, y,\n",
    "                yerr=yerr,\n",
    "                labels=labels,\n",
    "                data=data2,\n",
    "                data_label=data_label,\n",
    "                signals=signals[-max_signals_plotted:],\n",
    "                signal_labels=signal_labels[-max_signals_plotted:],\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                xlim=(110, 180),\n",
    "#                ylim=(0.0, 160.0),\n",
    "                ratio=True,\n",
    "                stack_signals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.hist1d(bins, y,\n",
    "                yerr=yerr,\n",
    "                labels=labels,\n",
    "                data=data2,\n",
    "                data_label=data_label,\n",
    "                signals=signals[-max_signals_plotted:],\n",
    "                signal_labels=signal_labels[-max_signals_plotted:],\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                xlim=(110, 180),\n",
    "#                ylim=(0.0, 160.0),\n",
    "                ratio=True,\n",
    "                stack_signals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ms, exclusions_exp, exclusions_obs = hep.stats.hypo_test_signal_scan(\n",
    "        signal_grid=signal_grid,\n",
    "        data=data2,\n",
    "        bkg_data=ytotal,\n",
    "        bkg_uncerts=yerr,\n",
    "        mu_bounds=mu_bounds_excl,\n",
    "        mu_step=mu_step_excl,\n",
    "        test_size=test_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.brazil(x=signal_ms, exp=exclusions_exp, obs=exclusions_obs,\n",
    "                xlabel=r'$m$  [GeV]',\n",
    "                ylabel=r'$\\mu\\ \\mathrm{excluded\\ at\\ 95\\%\\ CL}$',\n",
    "                yline=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $p_0$ for discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ms, p0s_exp, p0s_obs = hep.stats.discovery_p0_signal_scan(\n",
    "        signal_grid=signal_grid,\n",
    "        data=data2,\n",
    "        bkg_data=ytotal,\n",
    "        bkg_uncerts=yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 2-sigma bands, keep only 1-sigma\n",
    "p0s_exp = [ band[1:4] for band in p0s_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.brazil(x=signal_ms, exp=p0s_exp, obs=p0s_obs,\n",
    "                xlabel=r'$m$  [GeV]',\n",
    "                ylabel=r'Local $p_{0}$',\n",
    "                ylim=(1e-7, 1.0),\n",
    "                yscale='log',\n",
    "                yline=[1.0-scipy.stats.norm.cdf(z) for z in [2, 3, 4, 5]],\n",
    "                yline_label=[r'$%i\\sigma$' % (z) for z in [2, 3, 4, 5]],\n",
    "                fillstyle='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure best-fit signal strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_signal = signal_grid[(150.0,)]\n",
    "example_signal_pdf = hep.stats.make_pdf(bkg_data=ytotal, bkg_uncerts=yerr, signal_data=example_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twice_nlls, test_mus, mu_hat_band = hep.stats.twice_nll_mu_scan(\n",
    "                   pdf=example_signal_pdf,\n",
    "                   data=data2,\n",
    "                   mu_bounds=mu_bounds_fit,\n",
    "                   mu_step=mu_step_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.stats.plot_twice_nll(test_mus, twice_nlls,\n",
    "              xlabel='$\\mu$',\n",
    "              ylabel='$-2 \\Delta \\mathrm{ln} \\lambda(\\mu)$',\n",
    "              ylim=(0, 8),\n",
    "              yline=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ms, mu_hat_results = hep.stats.signal_strength_signal_scan(\n",
    "        signal_grid=signal_grid,\n",
    "        data=data2,\n",
    "        bkg_data=ytotal,\n",
    "        bkg_uncerts=yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.plot.brazil(x=signal_ms, obs=mu_hat_results,\n",
    "                xlabel=r'$m$  [GeV]',\n",
    "                ylabel=r'Signal strength $(\\hat{\\mu})$',\n",
    "                ylim=(-0.8, 2.0),\n",
    "                yline=[0.0, 1.0],\n",
    "                fillstyle='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "-   Cranmer, K. (2020). [Thumbnail of LHC statistical procedures](http://theoryandpractice.org/stats-ds-book/statistics/lhc_stats_thumbnail.html).\n",
    "-   Cowan, G. et al. (2010). Asymptotic formulae for likelihood-based tests of new physics. https://arxiv.org/abs/1007.1727\n",
    "-   https://pyhf.github.io/pyhf-tutorial/HelloWorld.html\n",
    "-   Cranmer, K. et al. (2012). HistFactory: A tool for creating statistical models for use with RooFit and RooStats. CERN-OPEN-2012-016. <https://cds.cern.ch/record/1456844>\n",
    "-   Heinrich, L., Feickert, M., & Stark, G. (2018). [pyhf](https://github.com/scikit-hep/pyhf). <https://scikit-hep.org/pyhf/>\n",
    "-   Feickert, M. (2018). pyhf: a pure Python implementation of HistFactory with tensors and autograd. <https://indico.cern.ch/event/759480/>\n",
    "-   <https://github.com/CoffeaTeam/coffea/blob/master/coffea/hist/plot.py>\n",
    "-   <https://scikit-hep.org/pyhf/examples/notebooks/multichannel-coupled-histo.html>\n",
    "-   <https://scikit-hep.org/pyhf/examples/notebooks/binderexample/StatisticalAnalysis.html>\n",
    "-   <https://github.com/scikit-hep/mplhep/blob/master/src/mplhep/plot.py>\n",
    "\n",
    "![](http://theoryandpractice.org/stats-ds-book/_images/LHC-stats-thumbnail.001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
